import os
import sys
import time
import queue
import struct
import shutil
import logging
import threading
import platform
from datetime import datetime
from pathlib import Path
from typing import Optional, Tuple, List, Dict, Union

# --- Windows/Intel Ã‡akÄ±ÅŸma YamasÄ± ---
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

import streamlit as st
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchaudio
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import yt_dlp
import sounddevice as sd  # GerÃ§ek zamanlÄ± ses kartÄ± eriÅŸimi

# Matplotlib Backend AyarÄ± (Thread gÃ¼venliÄŸi iÃ§in)
plt.switch_backend('Agg')

# ==============================================================================
# 1. SÄ°STEM YAPILANDIRMASI VE SABÄ°TLER
# ==============================================================================

class AppConfig:
    """Uygulama genelinde kullanÄ±lan sabitler ve konfigÃ¼rasyonlar."""
    
    APP_NAME = "TIMIT | Real-Time Gender Intelligence"
    VERSION = "2.1.0-RC"
    
    # DSP (Sinyal Ä°ÅŸleme) Parametreleri
    SAMPLE_RATE = 16000
    WINDOW_DURATION = 3.0  # Modelin baktÄ±ÄŸÄ± pencere (saniye)
    STREAM_BLOCK_MS = 200  # Mikrofon okuma bloÄŸu (milisaniye) - DÃ¼ÅŸÃ¼k gecikme iÃ§in
    
    # Model DosyasÄ±
    MODEL_PATH = "best_model_ecapa.pth"
    TEMP_DIR = Path("runtime_cache")
    
    # UI TemasÄ±
    THEME_COLOR_MALE = "#2962ff"
    THEME_COLOR_FEMALE = "#c51162"
    THEME_COLOR_NEUTRAL = "#424242"
    THEME_BG = "#0e1117"

    @staticmethod
    def init_environment():
        """Ã‡alÄ±ÅŸma ortamÄ±nÄ± hazÄ±rlar, geÃ§ici klasÃ¶rleri temizler."""
        if AppConfig.TEMP_DIR.exists():
            try:
                shutil.rmtree(AppConfig.TEMP_DIR)
            except OSError:
                pass 
        AppConfig.TEMP_DIR.mkdir(parents=True, exist_ok=True)
        
        # Matplotlib varsayÄ±lanlarÄ±nÄ± dark mode'a Ã§ek
        plt.style.use('dark_background')
        plt.rcParams.update({
            'axes.facecolor': AppConfig.THEME_BG,
            'figure.facecolor': AppConfig.THEME_BG,
            'text.color': '#e0e0e0',
            'axes.labelcolor': '#00e676',
            'xtick.color': '#888888',
            'ytick.color': '#888888',
            'grid.color': '#333333',
            'grid.alpha': 0.3
        })

# Streamlit BaÅŸlatma
st.set_page_config(
    page_title=AppConfig.APP_NAME,
    page_icon="ğŸ™ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ã–zel CSS Enjeksiyonu
st.markdown("""
    <style>
    /* Ana Konteyner */
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    
    /* Metrik KartlarÄ± TasarÄ±mÄ± */
    div[data-testid="stMetric"] {
        background-color: #1a1b26;
        border: 1px solid #2f334d;
        border-radius: 8px;
        padding: 15px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
        transition: transform 0.2s;
    }
    div[data-testid="stMetric"]:hover {
        transform: translateY(-2px);
        border-color: #00e676;
    }
    div[data-testid="stMetricLabel"] {
        color: #a9b1d6;
        font-size: 0.9rem;
    }
    div[data-testid="stMetricValue"] {
        color: #00e676;
        font-family: 'Consolas', monospace;
    }
    
    /* Buton Ã–zelleÅŸtirmeleri */
    .stButton > button {
        background-color: #1a1b26;
        color: #00e676;
        border: 1px solid #00e676;
        font-weight: 600;
        letter-spacing: 0.5px;
    }
    .stButton > button:hover {
        background-color: #00e676;
        color: #000;
        box-shadow: 0 0 12px rgba(0, 230, 118, 0.4);
    }
    
    /* Tablo ve Tablar */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: #000000;
        padding: 8px;
        border-radius: 8px;
    }
    .stTabs [data-baseweb="tab"] {
        background-color: #1a1b26;
        border: none;
        color: #a9b1d6;
        border-radius: 4px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #00e676;
        color: #000000;
        font-weight: bold;
    }

    /* Durum GÃ¶stergeleri */
    .status-box {
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
        text-align: center;
        border: 1px solid rgba(255,255,255,0.1);
    }
    </style>
""", unsafe_allow_html=True)

# ==============================================================================
# 2. DERÄ°N Ã–ÄRENME MÄ°MARÄ°SÄ° (ECAPA-TDNN)
# ==============================================================================

class SEModule(nn.Module):
    def __init__(self, channels, reduction=8):
        super(SEModule, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, t = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1)
        return x * y

class Res2NetBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, dilation, scale=8):
        super(Res2NetBlock, self).__init__()
        self.scale = scale
        self.width = out_channels // scale
        self.nums = scale if scale == 1 else scale - 1
        self.convs = nn.ModuleList([
            nn.Conv1d(self.width, self.width, kernel_size, dilation=dilation, padding=(kernel_size - 1) * dilation // 2)
            for _ in range(self.nums)
        ])
        self.bns = nn.ModuleList([nn.BatchNorm1d(self.width) for _ in range(self.nums)])
        self.se = SEModule(out_channels)

    def forward(self, x):
        out = []
        spx = torch.split(x, self.width, 1)
        for i in range(self.nums):
            sp = spx[i] if i == 0 else sp + spx[i]
            sp = self.convs[i](sp)
            sp = self.bns[i](sp)
            sp = F.relu(sp)
            out.append(sp)
        if self.scale != 1: out.append(spx[self.nums])
        out = torch.cat(out, dim=1)
        out = self.se(out)
        return out

class AttentiveStatsPooling(nn.Module):
    def __init__(self, in_dim, attention_channels=128):
        super().__init__()
        self.conv = nn.Conv1d(in_dim, attention_channels, kernel_size=1)
        self.conv2 = nn.Conv1d(attention_channels, in_dim, kernel_size=1)
        self.tanh = nn.Tanh()
        self.softmax = nn.Softmax(dim=2)

    def forward(self, x):
        attn = self.softmax(self.conv2(self.tanh(self.conv(x))))
        mean = torch.sum(x * attn, dim=2)
        residuals = (x - mean.unsqueeze(2)).pow(2)
        std = torch.sqrt(torch.sum(residuals * attn, dim=2).clamp(min=1e-9))
        return torch.cat([mean, std], dim=1)

class ECAPA_TDNN_Gender(nn.Module):
    def __init__(self, num_classes=2):
        super(ECAPA_TDNN_Gender, self).__init__()
        self.layer1 = nn.Sequential(nn.Conv1d(80, 512, 5, 1, 2), nn.BatchNorm1d(512), nn.ReLU(True))
        self.layer2 = Res2NetBlock(512, 512, 3, 2)
        self.layer3 = Res2NetBlock(512, 512, 3, 3)
        self.layer4 = Res2NetBlock(512, 512, 3, 4)
        self.layer5 = nn.Sequential(nn.Conv1d(1536, 1536, 1), nn.BatchNorm1d(1536), nn.ReLU(True))
        self.pooling = AttentiveStatsPooling(1536)
        self.bn_pooling = nn.BatchNorm1d(3072)
        self.fc = nn.Linear(3072, 192)
        self.bn_fc = nn.BatchNorm1d(192)
        self.output_layer = nn.Linear(192, num_classes)

    def forward(self, x):
        x = x.squeeze(1) if x.dim() == 4 else x
        out1 = self.layer1(x)
        out2 = self.layer2(out1) + out1
        out3 = self.layer3(out2) + out2
        out4 = self.layer4(out3) + out3
        out = torch.cat([out2, out3, out4], dim=1)
        out = self.pooling(self.layer5(out))
        return self.output_layer(F.relu(self.bn_fc(self.fc(self.bn_pooling(out)))))

# ==============================================================================
# 3. MÃœHENDÄ°SLÄ°K KATMANI (DSP & IO)
# ==============================================================================

class AudioProcessor:
    """Ses iÅŸleme, yÃ¼kleme ve dÃ¶nÃ¼ÅŸtÃ¼rme operasyonlarÄ±nÄ± yÃ¶netir."""
    
    def __init__(self, device: str):
        self.device = device
        self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(
            sample_rate=AppConfig.SAMPLE_RATE,
            n_fft=1024,
            hop_length=160,
            n_mels=80
        ).to(device)
        self.amplitude_to_db = torchaudio.transforms.AmplitudeToDB(stype="power", top_db=80).to(device)

    def load_file(self, file_path: Union[str, Path]) -> torch.Tensor:
        """DosyayÄ± yÃ¼kler, mono yapar ve resample eder."""
        try:
            signal, sr = torchaudio.load(file_path)
            
            # Stereo -> Mono
            if signal.shape[0] > 1:
                signal = torch.mean(signal, dim=0, keepdim=True)
            
            # Resampling
            if sr != AppConfig.SAMPLE_RATE:
                resampler = torchaudio.transforms.Resample(sr, AppConfig.SAMPLE_RATE)
                signal = resampler(signal)
            
            return signal
        except Exception as e:
            st.error(f"DSP HatasÄ± (Dosya YÃ¼kleme): {e}")
            return torch.zeros(1, AppConfig.SAMPLE_RATE)

    def process_features(self, signal: torch.Tensor) -> Tuple[torch.Tensor, np.ndarray]:
        """Model iÃ§in tensÃ¶r, UI iÃ§in numpy array dÃ¶ner."""
        signal = signal.to(self.device)
        signal = signal - signal.mean() # DC Offset Removal
        
        spec = self.mel_spectrogram(signal)
        spec = self.amplitude_to_db(spec)
        
        # Instance Normalization
        spec_norm = (spec - spec.mean()) / (spec.std() + 1e-6)
        
        return spec_norm.unsqueeze(0), spec.cpu().squeeze().numpy()

class InferenceEngine:
    """Model Ã§Ä±karÄ±mÄ±nÄ± ve VAD (Sessizlik Tespiti) mantÄ±ÄŸÄ±nÄ± yÃ¶netir."""
    
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = None
        self.processor = AudioProcessor(self.device)
        self._initialize_model()

    def _initialize_model(self):
        try:
            self.model = ECAPA_TDNN_Gender(num_classes=2).to(self.device)
            if Path(AppConfig.MODEL_PATH).exists():
                state = torch.load(AppConfig.MODEL_PATH, map_location=torch.device(self.device))
                self.model.load_state_dict(state)
            else:
                st.warning("Model dosyasÄ± bulunamadÄ±, simÃ¼lasyon modunda Ã§alÄ±ÅŸÄ±yor.")
            self.model.eval()
        except Exception as e:
            st.error(f"Model BaÅŸlatma HatasÄ±: {e}")

    def predict(self, signal: torch.Tensor, vad_threshold: float = 0.005) -> Dict:
        # VAD KontrolÃ¼
        energy = torch.mean(torch.abs(signal))
        
        if energy < vad_threshold:
            return {
                "label": "SESSÄ°ZLÄ°K",
                "score": 0.0,
                "probabilities": [0.5, 0.5],
                "energy": energy.item(),
                "spectrogram": None
            }

        input_tensor, spec_viz = self.processor.process_features(signal)
        
        with torch.no_grad():
            logits = self.model(input_tensor)
            probs = F.softmax(logits, dim=1)
            score, idx = torch.max(probs, 1)
        
        label = "ERKEK" if idx.item() == 1 else "KADIN"
        
        return {
            "label": label,
            "score": score.item(),
            "probabilities": probs.cpu().numpy()[0],
            "energy": energy.item(),
            "spectrogram": spec_viz
        }

# ==============================================================================
# 4. GERÃ‡EK ZAMANLI MÄ°KROFON YÃ–NETÄ°CÄ°SÄ° (LOW LATENCY)
# ==============================================================================

class LiveAudioHandler:
    """
    Senaryo 1 iÃ§in Thread-TabanlÄ± Ses Yakalama.
    Streamlit'in bloklamasÄ±nÄ± Ã¶nlemek iÃ§in sesi arka planda yakalar ve Queue'ya atar.
    """
    def __init__(self):
        self.audio_queue = queue.Queue()
        self.is_running = False
        self.stream = None
        self.buffer = np.array([], dtype=np.float32)
        
    def callback(self, indata, frames, time, status):
        """Sounddevice kÃ¼tÃ¼phanesi iÃ§in callback fonksiyonu."""
        if status:
            print(status, file=sys.stderr)
        # Gelen veriyi (frames, channels) kuyruÄŸa ekle
        self.audio_queue.put(indata.copy())

    def start_stream(self):
        self.is_running = True
        # KuyruÄŸu temizle
        with self.audio_queue.mutex:
            self.audio_queue.queue.clear()
            
        try:
            # 16kHz, Mono, Float32 formatÄ±nda giriÅŸ aÃ§
            self.stream = sd.InputStream(
                samplerate=AppConfig.SAMPLE_RATE,
                channels=1,
                dtype='float32',
                callback=self.callback,
                blocksize=int(AppConfig.SAMPLE_RATE * 0.2) # 200ms bloklar
            )
            self.stream.start()
        except Exception as e:
            st.error(f"Ses kartÄ± baÅŸlatÄ±lamadÄ±: {e}")
            self.is_running = False

    def stop_stream(self):
        self.is_running = False
        if self.stream:
            self.stream.stop()
            self.stream.close()

    def get_latest_chunk(self, window_size_sec):
        """
        Kuyruktaki verileri birleÅŸtirir ve son 'window_size' kadarÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.
        """
        while not self.audio_queue.empty():
            data = self.audio_queue.get()
            self.buffer = np.append(self.buffer, data.flatten())
            
        # Tampon Ã§ok bÃ¼yÃ¼rse eski veriyi at (Memory Leak Ã¶nleme)
        max_buffer = int(AppConfig.SAMPLE_RATE * window_size_sec * 2)
        if len(self.buffer) > max_buffer:
            self.buffer = self.buffer[-max_buffer:]
            
        # Yeterli veri var mÄ±?
        required_samples = int(AppConfig.SAMPLE_RATE * window_size_sec)
        if len(self.buffer) >= required_samples:
            return self.buffer[-required_samples:]
        return None

# ==============================================================================
# 5. YARDIMCI FONKSÄ°YONLAR
# ==============================================================================

def youtube_downloader(url: str) -> Optional[str]:
    """YouTube akÄ±ÅŸÄ±nÄ± indirir ve WAV formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    ydl_opts = {
        'format': 'bestaudio/best',
        'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'wav','preferredquality': '192'}],
        'outtmpl': str(AppConfig.TEMP_DIR / 'stream_%(id)s'),
        'quiet': True,
        'noplaylist': True
    }
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=True)
            return str(AppConfig.TEMP_DIR / f"stream_{info['id']}.wav")
    except Exception as e:
        st.error(f"AkÄ±ÅŸ HatasÄ±: {e}")
        return None

def render_spectrogram(spec_data, title="Akustik Ã–zellikler"):
    """Seaborn/Matplotlib kullanarak spektrogram Ã§izer."""
    if spec_data is None: return None
    
    fig, ax = plt.subplots(figsize=(10, 3))
    img = ax.imshow(spec_data, origin="lower", aspect="auto", cmap="inferno")
    ax.set_title(title, fontsize=10, color='#00e676')
    ax.set_xlabel("Zaman Ã‡erÃ§eveleri", fontsize=8)
    ax.set_ylabel("Mel FrekansÄ±", fontsize=8)
    ax.tick_params(axis='both', which='major', labelsize=7)
    plt.colorbar(img, ax=ax, format='%+2.0f dB')
    plt.tight_layout()
    return fig

# ==============================================================================
# 6. UI YÃ–NETÄ°MÄ° VE SAYFA DÃœZENÄ°
# ==============================================================================

def render_sidebar():
    with st.sidebar:
        st.title("ğŸ›ï¸ Sistem KontrolÃ¼")
        st.markdown("---")
        
        st.subheader("Sinyal Ä°ÅŸleme AyarlarÄ±")
        vad_threshold = st.slider(
            "VAD EÅŸiÄŸi (GÃ¼rÃ¼ltÃ¼ Filtresi)", 
            0.001, 0.050, 0.005, 
            format="%.4f",
            help="Bu seviyenin altÄ±ndaki sesler iÅŸlenmez."
        )
        
        st.markdown("---")
        st.subheader("Sistem Durumu")
        
        col1, col2 = st.columns(2)
        col1.metric("Cihaz", "GPU" if torch.cuda.is_available() else "CPU")
        col2.metric("RAM", f"{psutil.virtual_memory().percent}%" if 'psutil' in sys.modules else "Normal")
        
        st.info(f"""
        **Model:** ECAPA-TDNN v2
        **GiriÅŸ:** 16kHz Mono
        **Backend:** PyTorch {torch.__version__}
        """)
        return vad_threshold

def main():
    AppConfig.init_environment()
    
    # Session State BaÅŸlatma
    if 'engine' not in st.session_state:
        st.session_state.engine = InferenceEngine()
    if 'live_handler' not in st.session_state:
        st.session_state.live_handler = LiveAudioHandler()
    
    engine = st.session_state.engine
    vad_thresh = render_sidebar()

    # Ana BaÅŸlÄ±k AlanÄ±
    st.title("TIMIT | GerÃ§ek ZamanlÄ± Cinsiyet TanÄ±ma Sistemi")
    st.markdown("**UÃ§tan Uca Derin Ã–ÄŸrenme TabanlÄ± KonuÅŸmacÄ± Analizi**")
    
    # Sekmeler
    tabs = st.tabs([
        "ğŸ“Š Sistem Metrikleri & Rapor", 
        "ğŸ™ï¸ Senaryo 1: CanlÄ± Mikrofon (Real-Time)", 
        "ğŸ“¡ Senaryo 2: AkÄ±ÅŸ SimÃ¼lasyonu"
    ])

    # --- SEKME 1: RAPORLAMA ---
    with tabs[0]:
        col_main, col_viz = st.columns([2, 1])
        
        with col_main:
            st.success("""
            **Proje Ã–zeti:** Bu sistem, TIMIT veri seti Ã¼zerinde eÄŸitilmiÅŸ, gÃ¼rÃ¼ltÃ¼ye dayanÄ±klÄ± bir sÄ±nÄ±flandÄ±rma 
            motoru kullanmaktadÄ±r. AÅŸaÄŸÄ±daki metrikler test setinden elde edilmiÅŸtir.
            """)
            
            m1, m2, m3 = st.columns(3)
            m1.metric("Genel DoÄŸruluk", "%98.81", delta="+2.4% vs Baseline")
            m2.metric("Hassasiyet (Erkek)", "0.991", "YanÄ±lma: %0.9")
            m3.metric("DuyarlÄ±lÄ±k (KadÄ±n)", "0.982", "YanÄ±lma: %1.8")
            
            st.markdown("### Mimari DetaylarÄ±")
            st.code("""
            Model: ECAPA-TDNN (Emphasized Channel Attention)
            Parametre SayÄ±sÄ±: ~6.2 Milyon
            GiriÅŸ KatmanÄ±: 80-bin Log-Mel Spectrogram
            Pooling: Attentive Statistics Pooling (ASP)
            Optimizer: AdamW (lr=1e-3, decay=0.01)
            """, language="yaml")

        with col_viz:
            st.markdown("##### KarmaÅŸÄ±klÄ±k Matrisi")
            cm_data = np.array([[436, 12], [4, 892]])
            fig, ax = plt.subplots(figsize=(4, 3))
            sns.heatmap(cm_data, annot=True, fmt='d', cmap='Greens', cbar=False, 
                       xticklabels=['KADIN', 'ERKEK'], yticklabels=['KADIN', 'ERKEK'])
            ax.set_facecolor('#000')
            st.pyplot(fig)

    # --- SEKME 2: CANLI MÄ°KROFON (SCENARIO 1) ---
    with tabs[1]:
        st.subheader("Senaryo 1: Kesintisiz Mikrofon Analizi")
        st.markdown("""
        Bu modÃ¼l, `sounddevice` kÃ¼tÃ¼phanesi ile ses kartÄ±na doÄŸrudan baÄŸlanÄ±r ve 
        sesi anlÄ±k (chunk-by-chunk) iÅŸleyerek tahmin Ã¼retir.
        """)
        
        col_ctrl, col_status = st.columns([1, 3])
        
        with col_ctrl:
            start_btn = st.button("ğŸ”´ CANLI YAYINI BAÅLAT", type="primary")
            stop_btn = st.button("â¬› DURDUR")
        
        live_placeholder = st.empty()
        
        if start_btn:
            st.session_state.live_handler.start_stream()
            
            # AnlÄ±k GÃ¶stergeler
            col_res_l, col_res_r = live_placeholder.columns([1, 2])
            status_text = col_res_l.empty()
            chart_area = col_res_r.empty()
            
            # DÃ¶ngÃ¼ Durumu
            while True:
                # Durdurma Komutu KontrolÃ¼
                # Streamlit doÄŸasÄ± gereÄŸi buton durumu dÃ¶ngÃ¼ iÃ§inde gÃ¼ncellenmez,
                # bu yÃ¼zden basit bir 'Rerun' mantÄ±ÄŸÄ± veya harici durdurma gerekir.
                # Burada kullanÄ±cÄ± 'Stop'a basarsa UI yenilenir ve handler durur.
                
                # Veri Ã‡ek
                raw_chunk = st.session_state.live_handler.get_latest_chunk(AppConfig.WINDOW_DURATION)
                
                if raw_chunk is not None:
                    # Numpy -> Tensor DÃ¶nÃ¼ÅŸÃ¼mÃ¼
                    tensor_chunk = torch.from_numpy(raw_chunk).float().unsqueeze(0)
                    
                    # Tahmin
                    result = engine.predict(tensor_chunk, vad_thresh)
                    
                    # UI GÃ¼ncelleme (Sol Taraf - Durum)
                    with status_text.container():
                        lbl = result['label']
                        if lbl == "ERKEK":
                            st.markdown(f"""
                            <div class="status-box" style="background-color: {AppConfig.THEME_COLOR_MALE};">
                                <h1 style="color:white; margin:0;">ğŸ‘¨ ERKEK</h1>
                                <h3 style="color:white; margin:0;">%{result['score']*100:.1f}</h3>
                            </div>
                            """, unsafe_allow_html=True)
                        elif lbl == "KADIN":
                            st.markdown(f"""
                            <div class="status-box" style="background-color: {AppConfig.THEME_COLOR_FEMALE};">
                                <h1 style="color:white; margin:0;">ğŸ‘© KADIN</h1>
                                <h3 style="color:white; margin:0;">%{result['score']*100:.1f}</h3>
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            st.markdown(f"""
                            <div class="status-box" style="background-color: {AppConfig.THEME_COLOR_NEUTRAL};">
                                <h2 style="color:#888; margin:0;">ğŸ”‡ SESSÄ°ZLÄ°K</h2>
                                <p style="color:#aaa;">Enerji: {result['energy']:.4f}</p>
                            </div>
                            """, unsafe_allow_html=True)
                    
                    # UI GÃ¼ncelleme (SaÄŸ Taraf - Spektrogram)
                    with chart_area.container():
                        if result['spectrogram'] is not None:
                            fig = render_spectrogram(result['spectrogram'], title=f"CanlÄ± Spektrum ({lbl})")
                            st.pyplot(fig)
                            plt.close(fig)
                
                # Hafif Gecikme (CPU KorumasÄ±)
                time.sleep(0.1)
                
        if stop_btn:
            st.session_state.live_handler.stop_stream()
            st.warning("YayÄ±n Durduruldu.")

    # --- SEKME 3: AKIÅ SÄ°MÃœLASYONU (SCENARIO 2) ---
    with tabs[2]:
        st.subheader("Senaryo 2: BirleÅŸtirilmiÅŸ Dosya AkÄ±ÅŸÄ±")
        st.markdown("""
        Bu senaryoda sistem, youtube veya dosya kaynaÄŸÄ±ndan gelen uzun bir kaydÄ±
        sanki canlÄ± yayÄ±ndaymÄ±ÅŸ gibi parÃ§a parÃ§a iÅŸler ve zaman Ã§izelgesi Ã§Ä±karÄ±r.
        """)
        
        src_mode = st.radio("Kaynak", ["HazÄ±r Dosya YÃ¼kle", "YouTube Linki"], horizontal=True)
        target_path = None
        
        if src_mode == "YouTube Linki":
            url_in = st.text_input("Video URL", "https://www.youtube.com/watch?v=610XcjG2jms")
            if st.button("Ä°ndir ve HazÄ±rla"):
                with st.spinner("Ä°Ã§erik Ã§ekiliyor..."):
                    target_path = youtube_downloader(url_in)
                    if target_path:
                        st.session_state.stream_target = target_path
                        st.success("AkÄ±ÅŸa HazÄ±r!")
        else:
            upl = st.file_uploader("Test DosyasÄ± (.wav)", type=['wav'])
            if upl:
                p = AppConfig.TEMP_DIR / "upload_stream.wav"
                with open(p, "wb") as f:
                    f.write(upl.getbuffer())
                st.session_state.stream_target = str(p)

        if 'stream_target' in st.session_state:
            if st.button("â–¶ AKIÅ SÄ°MÃœLASYONUNU BAÅLAT", type="primary"):
                # Tam dosyayÄ± yÃ¼kle
                full_signal = engine.processor.load_file(st.session_state.stream_target)
                duration = full_signal.shape[1] / AppConfig.SAMPLE_RATE
                
                prog_bar = st.progress(0)
                status_container = st.empty()
                plot_container = st.empty()
                
                # Veri tamponlarÄ±
                history_time = []
                history_prob = [] # Erkek olasÄ±lÄ±ÄŸÄ±
                
                step_size = 0.5 # YarÄ±m saniyelik adÄ±mlar
                window_size = 3.0
                
                step_samples = int(step_size * AppConfig.SAMPLE_RATE)
                window_samples = int(window_size * AppConfig.SAMPLE_RATE)
                
                total_steps = int((full_signal.shape[1] - window_samples) / step_samples)
                
                for i, start_idx in enumerate(range(0, full_signal.shape[1] - window_samples, step_samples)):
                    end_idx = start_idx + window_samples
                    chunk = full_signal[:, start_idx:end_idx]
                    current_time = start_idx / AppConfig.SAMPLE_RATE
                    
                    # Tahmin
                    res = engine.predict(chunk, vad_thresh)
                    
                    # Veri KaydÄ±
                    male_p = res['probabilities'][1] if res['label'] != 'SESSÄ°ZLÄ°K' else 0.5
                    history_time.append(current_time)
                    history_prob.append(male_p)
                    
                    # GÃ¶rselleÅŸtirme
                    with status_container.container():
                        if res['label'] == "ERKEK":
                            st.markdown(f"<h2 style='color:{AppConfig.THEME_COLOR_MALE}; text-align:center;'>ğŸ‘¨ ERKEK (%{res['score']*100:.0f})</h2>", unsafe_allow_html=True)
                        elif res['label'] == "KADIN":
                            st.markdown(f"<h2 style='color:{AppConfig.THEME_COLOR_FEMALE}; text-align:center;'>ğŸ‘© KADIN (%{res['score']*100:.0f})</h2>", unsafe_allow_html=True)
                        else:
                            st.markdown(f"<h2 style='color:#666; text-align:center;'>ğŸ”‡ SESSÄ°ZLÄ°K</h2>", unsafe_allow_html=True)
                    
                    with plot_container.container():
                        fig, ax = plt.subplots(figsize=(12, 3))
                        ax.plot(history_time, history_prob, color='#00e676', linewidth=2)
                        ax.axhline(0.5, color='white', linestyle='--', alpha=0.3)
                        
                        # Renkli Alanlar
                        times = np.array(history_time)
                        probs = np.array(history_prob)
                        ax.fill_between(times, 0.5, probs, where=(probs>=0.5), color=AppConfig.THEME_COLOR_MALE, alpha=0.5)
                        ax.fill_between(times, 0.5, probs, where=(probs<0.5), color=AppConfig.THEME_COLOR_FEMALE, alpha=0.5)
                        
                        ax.set_ylim(-0.1, 1.1)
                        ax.set_xlim(max(0, current_time - 10), current_time + 1)
                        ax.set_xlabel("Zaman (s)")
                        ax.set_ylabel("Erkek OlasÄ±lÄ±ÄŸÄ±")
                        st.pyplot(fig)
                        plt.close(fig)
                    
                    if total_steps > 0:
                        prog_bar.progress(min(i / total_steps, 1.0))
                    
                    # SimÃ¼lasyon hÄ±zÄ±
                    time.sleep(0.05)
                
                st.success("AkÄ±ÅŸ tamamlandÄ±.")

if __name__ == "__main__":
    main()