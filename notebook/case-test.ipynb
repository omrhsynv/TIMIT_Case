{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T14:59:21.539668Z",
     "iopub.status.busy": "2026-01-14T14:59:21.538897Z",
     "iopub.status.idle": "2026-01-14T15:00:44.588122Z",
     "shell.execute_reply": "2026-01-14T15:00:44.587299Z",
     "shell.execute_reply.started": "2026-01-14T14:59:21.539642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- SABÄ°TLER ---\n",
    "SAMPLE_RATE = 16000\n",
    "TRIM_DB = 25\n",
    "OUTPUT_DIR = Path(\"/kaggle/working/processed_timit\")\n",
    "\n",
    "def find_dataset_root(start_dir=\"/kaggle/input\"):\n",
    "    \"\"\"\n",
    "    TIMIT klasÃ¶rÃ¼nÃ¼ sistemde arayÄ±p bulur.\n",
    "    Path hatasÄ±nÄ± %100 Ã§Ã¶zer.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” TIMIT veri seti aranÄ±yor...\")\n",
    "    for root, dirs, files in os.walk(start_dir):\n",
    "        # EÄŸer bir klasÃ¶rde hem 'TRAIN' hem 'TEST' varsa orasÄ± doÄŸru yerdir\n",
    "        if \"TRAIN\" in dirs and \"TEST\" in dirs:\n",
    "            found_path = Path(root)\n",
    "            print(f\"âœ… Veri seti bulundu: {found_path}\")\n",
    "            return found_path\n",
    "    \n",
    "    return Path(\"/kaggle/input/timitd/data/lisa/data/timit/raw/TIMIT\")\n",
    "\n",
    "def get_gender_from_folder(folder_name, spkr_map):\n",
    "    \"\"\"\n",
    "    Cinsiyeti bulmak iÃ§in Ã¶nce haritaya bakar, bulamazsa klasÃ¶r adÄ±na bakar.\n",
    "    TIMIT klasÃ¶rleri genelde 'M' veya 'F' ile baÅŸlar (Ã¶rn: FCJF0 -> Female).\n",
    "    \"\"\"\n",
    "    # 1. YÃ¶ntem: Tam eÅŸleÅŸme (spkrinfo.txt)\n",
    "    if folder_name in spkr_map:\n",
    "        return spkr_map[folder_name]\n",
    "    \n",
    "    if len(folder_name) > 1 and folder_name[1:] in spkr_map:\n",
    "        return spkr_map[folder_name[1:]]\n",
    "\n",
    "    # 3. YÃ¶ntem: KlasÃ¶r baÅŸ harfi (Fallback)\n",
    "    if folder_name.upper().startswith(\"M\"):\n",
    "        return \"M\"\n",
    "    elif folder_name.upper().startswith(\"F\"):\n",
    "        return \"F\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "def parse_spkrinfo(doc_path):\n",
    "    spkr_map = {}\n",
    "    try:\n",
    "        # BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf duyarlÄ± arama\n",
    "        info_files = list(doc_path.glob(\"spkrinfo.txt\")) + list(doc_path.glob(\"SPKRINFO.TXT\"))\n",
    "        if not info_files:\n",
    "            print(\"âš ï¸ spkrinfo.txt bulunamadÄ±, klasÃ¶r isimlerinden cinsiyet tahmini yapÄ±lacak.\")\n",
    "            return {}\n",
    "\n",
    "        with open(info_files[0], 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if not parts or line.startswith(';'): continue\n",
    "                # ID (Ã¶rn: CJF0) -> Sex (M/F)\n",
    "                spkr_map[parts[0]] = parts[1]\n",
    "        return spkr_map\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Metadata okunamadÄ±: {e}\")\n",
    "        return {}\n",
    "\n",
    "def main():\n",
    "    # 1. Veri setini bul\n",
    "    ROOT_DIR = find_dataset_root()\n",
    "    \n",
    "    # 2. Metadata oku\n",
    "    spkr_map = parse_spkrinfo(ROOT_DIR / \"DOC\")\n",
    "    \n",
    "    # Ä°statistikler\n",
    "    stats = {\"train\": {\"M\": 0, \"F\": 0}, \"test\": {\"M\": 0, \"F\": 0}}\n",
    "    \n",
    "    # Ã‡Ä±ktÄ± klasÃ¶rÃ¼nÃ¼ temizle/oluÅŸtur\n",
    "    if OUTPUT_DIR.exists():\n",
    "        shutil.rmtree(OUTPUT_DIR)\n",
    "    \n",
    "    print(\"\\nğŸš€ Ä°ÅŸleme BaÅŸlÄ±yor...\")\n",
    "    \n",
    "    for split in [\"TRAIN\", \"TEST\"]:\n",
    "        split_dir = ROOT_DIR / split\n",
    "        if not split_dir.exists():\n",
    "            print(f\"âŒ {split} klasÃ¶rÃ¼ bulunamadÄ±!\")\n",
    "            continue\n",
    "\n",
    "        # BÃ¶lge klasÃ¶rleri (DR1, DR2...)\n",
    "        regions = [d for d in split_dir.iterdir() if d.is_dir()]\n",
    "        \n",
    "        for dr in tqdm(regions, desc=f\"Processing {split}\"):\n",
    "            # KonuÅŸmacÄ± klasÃ¶rleri\n",
    "            speakers = [s for s in dr.iterdir() if s.is_dir()]\n",
    "            \n",
    "            for spkr in speakers:\n",
    "                # Cinsiyet Tespiti\n",
    "                gender = get_gender_from_folder(spkr.name, spkr_map)\n",
    "                if not gender:\n",
    "                    continue # Cinsiyet bilinemiyorsa atla\n",
    "                \n",
    "                # DosyalarÄ± bul (WAV veya wav)\n",
    "                # BÃ¼yÃ¼k kÃ¼Ã§Ã¼k harf duyarsÄ±z glob iÃ§in list comprehension\n",
    "                wav_files = [f for f in spkr.glob(\"*\") if f.suffix.lower() == \".wav\"]\n",
    "                \n",
    "                for wav_path in wav_files:\n",
    "                    # SA CÃ¼mlesi KontrolÃ¼ (Dosya adÄ±nda SA var mÄ±?)\n",
    "                    if \"SA\" in wav_path.name.upper().split(\".\")[0]: \n",
    "                        continue\n",
    "                        \n",
    "                    # Ä°ÅŸleme\n",
    "                    try:\n",
    "                        y, sr = librosa.load(wav_path, sr=SAMPLE_RATE)\n",
    "                        y_trim, _ = librosa.effects.trim(y, top_db=TRIM_DB)\n",
    "                        \n",
    "                        # Ã‡ok kÄ±sa dosyalarÄ± atla (<0.5sn)\n",
    "                        if len(y_trim) < 0.5 * SAMPLE_RATE:\n",
    "                            continue\n",
    "                            \n",
    "                        # Kaydet\n",
    "                        label = \"male\" if gender == \"M\" else \"female\"\n",
    "                        save_dir = OUTPUT_DIR / split.lower() / label\n",
    "                        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "                        \n",
    "                        out_name = f\"{spkr.name}_{wav_path.name}\"\n",
    "                        sf.write(save_dir / out_name, y_trim, SAMPLE_RATE)\n",
    "                        \n",
    "                        stats[split.lower()][gender] += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Hata: {wav_path.name} -> {e}\")\n",
    "\n",
    "    print(\"\\nâœ… Ä°ÅLEM TAMAMLANDI!\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"TRAIN -> Erkek: {stats['train']['M']}, KadÄ±n: {stats['train']['F']}\")\n",
    "    print(f\"TEST  -> Erkek: {stats['test']['M']}, KadÄ±n: {stats['test']['F']}\")\n",
    "    print(f\"Veriler: {OUTPUT_DIR}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T15:12:02.345892Z",
     "iopub.status.busy": "2026-01-14T15:12:02.345628Z",
     "iopub.status.idle": "2026-01-14T15:12:02.998476Z",
     "shell.execute_reply": "2026-01-14T15:12:02.997757Z",
     "shell.execute_reply.started": "2026-01-14T15:12:02.345876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# --- KONFIGURASYON ---\n",
    "DATA_ROOT = Path(\"/kaggle/working/processed_timit\")\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION = 3.0  \n",
    "NUM_SAMPLES = int(SAMPLE_RATE * DURATION)\n",
    "N_MELS = 80    \n",
    "\n",
    "class TimitGenderDataset(Dataset):\n",
    "    def __init__(self, subset=\"train\", transform=None):\n",
    "        self.subset_path = DATA_ROOT / subset\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.transform = transform \n",
    "\n",
    "        if not self.subset_path.exists():\n",
    "            raise FileNotFoundError(f\"KlasÃ¶r yok: {self.subset_path}\")\n",
    "\n",
    "        print(f\"ğŸ“‚ {subset.upper()} verisi taranÄ±yor...\")\n",
    "\n",
    "        self.class_counts = [0, 0] # [Female, Male]\n",
    "        \n",
    "        for label_code, label_name in enumerate([\"female\", \"male\"]):\n",
    "            class_dir = self.subset_path / label_name\n",
    "            if not class_dir.exists(): continue\n",
    "                \n",
    "            class_files = list(class_dir.glob(\"*.wav\")) + list(class_dir.glob(\"*.WAV\"))\n",
    "            \n",
    "            count = len(class_files)\n",
    "            print(f\"   -> {label_name}: {count} dosya\")\n",
    "            \n",
    "            self.files.extend(class_files)\n",
    "            self.labels.extend([label_code] * count)\n",
    "            self.class_counts[label_code] = count\n",
    "            \n",
    "        if len(self.files) == 0:\n",
    "            raise ValueError(f\"âŒ {subset} setinde hiÃ§ dosya bulunamadÄ±! (UzantÄ± hatasÄ± olabilir mi?)\")\n",
    "\n",
    "        # Spektrogram\n",
    "        self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=SAMPLE_RATE, n_fft=1024, hop_length=160, n_mels=N_MELS\n",
    "        )\n",
    "        self.db_transform = torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def _cut_or_pad(self, signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < NUM_SAMPLES:\n",
    "            num_repeats = int(NUM_SAMPLES / length_signal) + 1\n",
    "            padded_signal = signal.repeat(1, num_repeats)\n",
    "            signal = padded_signal[:, :NUM_SAMPLES]\n",
    "        elif length_signal > NUM_SAMPLES:\n",
    "            start = random.randint(0, length_signal - NUM_SAMPLES)\n",
    "            signal = signal[:, start:start + NUM_SAMPLES]\n",
    "        return signal\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.files[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        signal, sr = torchaudio.load(file_path)\n",
    "        if sr != SAMPLE_RATE:\n",
    "            signal = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(signal)\n",
    "        signal = self._cut_or_pad(signal)\n",
    "\n",
    "        spec = self.melspec(signal)\n",
    "        spec = self.db_transform(spec) \n",
    "\n",
    "        if self.transform:\n",
    "            spec = self.transform(spec)\n",
    "            \n",
    "        mean = spec.mean()\n",
    "        std = spec.std()\n",
    "        spec = (spec - mean) / (std + 1e-6)\n",
    "\n",
    "        return spec, label\n",
    "\n",
    "# --- AUGMENTATION ---\n",
    "train_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=35)\n",
    ")\n",
    "\n",
    "def get_dataloaders(batch_size=32):\n",
    "    print(\"\\n--- DATASET OLUÅTURULUYOR ---\")\n",
    "    train_ds = TimitGenderDataset(\"train\", transform=train_transforms)\n",
    "    test_ds = TimitGenderDataset(\"test\", transform=None)\n",
    "    \n",
    "    # Dengesizlik Ã‡Ã¶zÃ¼mÃ¼\n",
    "    counts = train_ds.class_counts\n",
    "    # BÃ¶lme hatasÄ±nÄ± Ã¶nle (if count > 0)\n",
    "    weights = [1.0/c if c > 0 else 0 for c in counts]\n",
    "    \n",
    "    sample_weights = [weights[label] for label in train_ds.labels]\n",
    "    \n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=torch.DoubleTensor(sample_weights),\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, num_workers=2)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "def visualize_sample():\n",
    "    try:\n",
    "        train_loader, _ = get_dataloaders(batch_size=4)\n",
    "        specs, labels = next(iter(train_loader))\n",
    "        \n",
    "        print(f\"\\nâœ… BAÅARILI! Batch Åekli: {specs.shape}\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.imshow(specs[0].squeeze().numpy(), cmap='inferno', origin='lower')\n",
    "        plt.title(f\"Log-Mel Spektrogram (Label: {'Erkek' if labels[0]==1 else 'KadÄ±n'})\")\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ HATA: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T15:16:17.470335Z",
     "iopub.status.busy": "2026-01-14T15:16:17.469985Z",
     "iopub.status.idle": "2026-01-14T15:16:18.527718Z",
     "shell.execute_reply": "2026-01-14T15:16:18.527059Z",
     "shell.execute_reply.started": "2026-01-14T15:16:17.470313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, t = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y\n",
    "\n",
    "class Res2NetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation, scale=8):\n",
    "        super(Res2NetBlock, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.width = out_channels // scale\n",
    "        self.nums = scale if scale == 1 else scale - 1\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(self.width, self.width, kernel_size, dilation=dilation, padding=(kernel_size - 1) * dilation // 2)\n",
    "            for _ in range(self.nums)\n",
    "        ])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(self.width) for _ in range(self.nums)])\n",
    "        self.se = SEModule(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        spx = torch.split(x, self.width, 1)\n",
    "        for i in range(self.nums):\n",
    "            if i == 0:\n",
    "                sp = spx[i]\n",
    "            else:\n",
    "                sp = sp + spx[i]\n",
    "            sp = self.convs[i](sp)\n",
    "            sp = self.bns[i](sp)\n",
    "            sp = F.relu(sp)\n",
    "            out.append(sp)\n",
    "        \n",
    "        if self.scale != 1:\n",
    "            out.append(spx[self.nums])\n",
    "            \n",
    "        out = torch.cat(out, dim=1)\n",
    "        out = self.se(out)\n",
    "        return out\n",
    "\n",
    "class AttentiveStatsPooling(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, attention_channels=128):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_dim, attention_channels, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(attention_channels, in_dim, kernel_size=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (Batch, Channels, Time)\n",
    "        \n",
    "        # 1. Dikkat SkorlarÄ±nÄ± Hesapla\n",
    "        attn = self.conv(x)\n",
    "        attn = self.tanh(attn)\n",
    "        attn = self.conv2(attn)\n",
    "        attn = self.softmax(attn) # (Batch, Channels, Time)\n",
    "\n",
    "        # 2. AÄŸÄ±rlÄ±klÄ± Ortalama (Mean)\n",
    "        # sum(x * w) -> (Batch, Channels)\n",
    "        mean = torch.sum(x * attn, dim=2)\n",
    "        \n",
    "        # 3. AÄŸÄ±rlÄ±klÄ± Standart Sapma (Std)\n",
    "        # Varyans = sum(w * (x - mean)^2)\n",
    "        # Yayma (Broadcasting): (B, C, T) - (B, C, 1) = (B, C, T)\n",
    "        residuals = (x - mean.unsqueeze(2)).pow(2)\n",
    "        weighted_residuals = torch.sum(residuals * attn, dim=2) # (Batch, Channels)\n",
    "        \n",
    "        std = torch.sqrt(weighted_residuals.clamp(min=1e-9))\n",
    "        \n",
    "        # 4. BirleÅŸtir\n",
    "        return torch.cat([mean, std], dim=1)\n",
    "\n",
    "class ECAPA_TDNN_Gender(nn.Module):\n",
    "    def __init__(self, input_channels=80, channels=512, emb_dim=192, num_classes=2):\n",
    "        super(ECAPA_TDNN_Gender, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, channels, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = Res2NetBlock(channels, channels, kernel_size=3, dilation=2, scale=8)\n",
    "        self.layer3 = Res2NetBlock(channels, channels, kernel_size=3, dilation=3, scale=8)\n",
    "        self.layer4 = Res2NetBlock(channels, channels, kernel_size=3, dilation=4, scale=8)\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv1d(3 * channels, 1536, kernel_size=1),\n",
    "            nn.BatchNorm1d(1536),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.pooling = AttentiveStatsPooling(1536)\n",
    "        self.bn_pooling = nn.BatchNorm1d(1536 * 2)\n",
    "\n",
    "        self.fc = nn.Linear(1536 * 2, emb_dim)\n",
    "        self.bn_fc = nn.BatchNorm1d(emb_dim)\n",
    "        self.output_layer = nn.Linear(emb_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (Batch, 1, Freq, Time) -> (Batch, Freq, Time)\n",
    "        if x.dim() == 4:\n",
    "            x = x.squeeze(1) \n",
    "\n",
    "        out1 = self.layer1(x)\n",
    "        out2 = self.layer2(out1) + out1\n",
    "        out3 = self.layer3(out2) + out2\n",
    "        out4 = self.layer4(out3) + out3\n",
    "\n",
    "        out = torch.cat([out2, out3, out4], dim=1)\n",
    "        out = self.layer5(out)\n",
    "        \n",
    "        out = self.pooling(out)\n",
    "        out = self.bn_pooling(out)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        out = self.bn_fc(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        logits = self.output_layer(out)\n",
    "        return logits\n",
    "\n",
    "# --- TEST BLOÄU ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸ—ï¸ ECAPA-TDNN Modeli (V2) Ä°nÅŸa Ediliyor...\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = ECAPA_TDNN_Gender(num_classes=2).to(device)\n",
    "    \n",
    "    dummy_input = torch.randn(4, 1, 80, 301).to(device)\n",
    "    \n",
    "    try:\n",
    "        output = model(dummy_input)\n",
    "        print(f\"âœ… GÄ°RÄ°Å: {dummy_input.shape}\")\n",
    "        print(f\"âœ… Ã‡IKIÅ: {output.shape}\") \n",
    "        \n",
    "        if output.shape == (4, 2):\n",
    "            print(\"ğŸš€ Model MimarisÄ± DOÄRULANDI! EÄŸitime hazÄ±rÄ±z.\")\n",
    "        else:\n",
    "            print(\"âŒ Boyut hatasÄ± devam ediyor.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ HATA: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T15:17:35.375837Z",
     "iopub.status.busy": "2026-01-14T15:17:35.375290Z",
     "iopub.status.idle": "2026-01-14T15:26:12.232631Z",
     "shell.execute_reply": "2026-01-14T15:26:12.231575Z",
     "shell.execute_reply.started": "2026-01-14T15:17:35.375814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# --- AYARLAR (Rapordaki Tablo 1'e GÃ¶re) ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 0.01\n",
    "EPOCHS = 15 # HÄ±zlÄ± sonuÃ§ iÃ§in 15 yeterli (TIMIT kÃ¼Ã§Ã¼k bir veri seti)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def train_model():\n",
    "    print(f\"ğŸ”¥ EÄŸitim BaÅŸlÄ±yor... (Cihaz: {DEVICE})\")\n",
    "    \n",
    "    # 1. Veri YÃ¼kleyicileri Al\n",
    "    train_loader, test_loader = get_dataloaders(batch_size=BATCH_SIZE)\n",
    "    print(f\"   -> EÄŸitim AdÄ±mÄ± SayÄ±sÄ±: {len(train_loader)}\")\n",
    "    \n",
    "    # 2. Modeli BaÅŸlat\n",
    "    model = ECAPA_TDNN_Gender(num_classes=2).to(DEVICE)\n",
    "    \n",
    "    # 3. KayÄ±p Fonksiyonu, Optimizer ve Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # Takip DeÄŸiÅŸkenleri\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    history = {'train_loss': [], 'val_acc': []}\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- EÄÄ°TÄ°M DÃ–NGÃœSÃœ ---\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "        # --- TRAIN ---\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        # Tqdm barÄ±\n",
    "        pbar = tqdm(train_loader, desc=\"EÄŸitiliyor\", leave=False)\n",
    "        \n",
    "        for inputs, labels in pbar:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            # SÄ±fÄ±rla -> Ä°leri -> Hata -> Geri -> GÃ¼ncelle\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Ä°statistikler\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_train += torch.sum(preds == labels.data)\n",
    "            total_train += labels.size(0)\n",
    "            \n",
    "            # Bar gÃ¼ncelle\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = correct_train.double() / total_train\n",
    "        \n",
    "        # --- VALIDATION (TEST) ---\n",
    "        model.eval()\n",
    "        running_corrects = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_acc = running_corrects.double() / len(test_loader.dataset)\n",
    "        \n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['val_acc'].append(epoch_acc.item())\n",
    "        \n",
    "        print(f\"Loss: {epoch_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {epoch_acc:.4f}\")\n",
    "        \n",
    "        # Scheduler AdÄ±mÄ±\n",
    "        scheduler.step()\n",
    "        \n",
    "        # En iyi modeli kaydet\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), \"best_model_ecapa.pth\")\n",
    "            print(\"âœ… Yeni En Ä°yi Model Kaydedildi!\")\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f\"\\nğŸ EÄŸitim TamamlandÄ±! SÃ¼re: {time_elapsed // 60:.0f}dk {time_elapsed % 60:.0f}sn\")\n",
    "    print(f\"ğŸ† En YÃ¼ksek Test DoÄŸruluÄŸu (Val Acc): {best_acc:.4f}\")\n",
    "    \n",
    "    # En iyi aÄŸÄ±rlÄ±klarÄ± yÃ¼kle\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # EÄŸer Ã¶nceki hÃ¼crelerden fonksiyonlar hafÄ±zadaysa doÄŸrudan Ã§alÄ±ÅŸÄ±r\n",
    "    trained_model, history = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T15:30:20.222938Z",
     "iopub.status.busy": "2026-01-14T15:30:20.222643Z",
     "iopub.status.idle": "2026-01-14T15:30:38.989182Z",
     "shell.execute_reply": "2026-01-14T15:30:38.988545Z",
     "shell.execute_reply.started": "2026-01-14T15:30:20.222916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class GenderPredictor:\n",
    "    def __init__(self, model_path, device=None):\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Modeli BaÅŸlat\n",
    "        self.model = ECAPA_TDNN_Gender(num_classes=2).to(self.device)\n",
    "        \n",
    "        # AÄŸÄ±rlÄ±klarÄ± YÃ¼kle (Hata kontrolÃ¼ ile)\n",
    "        if not Path(model_path).exists():\n",
    "            raise FileNotFoundError(f\"Model dosyasÄ± bulunamadÄ±: {model_path}\")\n",
    "            \n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.sample_rate = 16000\n",
    "        self.duration = 3.0\n",
    "        self.num_samples = int(self.sample_rate * self.duration)\n",
    "        \n",
    "        # DÃ¶nÃ¼ÅŸÃ¼m AraÃ§larÄ±\n",
    "        self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=self.sample_rate, n_fft=1024, hop_length=160, n_mels=80\n",
    "        ).to(self.device)\n",
    "        self.db_transform = torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80).to(self.device)\n",
    "\n",
    "    def preprocess(self, file_path):\n",
    "        signal, sr = torchaudio.load(file_path)\n",
    "        signal = signal.to(self.device)\n",
    "        \n",
    "        if sr != self.sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.sample_rate).to(self.device)\n",
    "            signal = resampler(signal)\n",
    "            \n",
    "        length = signal.shape[1]\n",
    "        if length < self.num_samples:\n",
    "            repeats = int(self.num_samples / length) + 1\n",
    "            signal = signal.repeat(1, repeats)\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        else:\n",
    "            # Ortadan kes\n",
    "            start = (length - self.num_samples) // 2\n",
    "            signal = signal[:, start:start + self.num_samples]\n",
    "            \n",
    "        spec = self.melspec(signal)\n",
    "        spec = self.db_transform(spec)\n",
    "        \n",
    "        mean = spec.mean()\n",
    "        std = spec.std()\n",
    "        spec = (spec - mean) / (std + 1e-6)\n",
    "        \n",
    "        return spec.unsqueeze(0)\n",
    "\n",
    "    def predict(self, file_path):\n",
    "        spec = self.preprocess(file_path)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(spec)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            \n",
    "        score, pred_idx = torch.max(probs, 1)\n",
    "        label = \"Erkek\" if pred_idx.item() == 1 else \"KadÄ±n\"\n",
    "        return label, score.item()\n",
    "\n",
    "def evaluate_on_test_set(predictor):\n",
    "    print(\"ğŸ” Test Seti Analiz Ediliyor...\")\n",
    "    \n",
    "    test_root = Path(\"/kaggle/working/processed_timit/test\")\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    files = []\n",
    "    \n",
    "    # Her iki sÄ±nÄ±fÄ± gez\n",
    "    for label_code, label_name in enumerate([\"female\", \"male\"]):\n",
    "        folder = test_root / label_name\n",
    "        \n",
    "        wavs = list(folder.glob(\"*.wav\")) + list(folder.glob(\"*.WAV\"))\n",
    "        \n",
    "        print(f\"   -> {label_name}: {len(wavs)} dosya test ediliyor...\")\n",
    "        \n",
    "        for wav in wavs:\n",
    "            try:\n",
    "                pred_label, conf = predictor.predict(str(wav))\n",
    "                pred_code = 1 if pred_label == \"Erkek\" else 0\n",
    "                \n",
    "                y_true.append(label_code)\n",
    "                y_pred.append(pred_code)\n",
    "                files.append(wav.name)\n",
    "            except Exception as e:\n",
    "                print(f\"Hata ({wav.name}): {e}\")\n",
    "\n",
    "    # Grafik Ã‡izimi\n",
    "    if len(y_true) > 0:\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=['KadÄ±n (Tahmin)', 'Erkek (Tahmin)'],\n",
    "                    yticklabels=['KadÄ±n (GerÃ§ek)', 'Erkek (GerÃ§ek)'])\n",
    "        plt.title('TIMIT SonuÃ§ Matrisi')\n",
    "        plt.ylabel('GerÃ§ek')\n",
    "        plt.xlabel('Tahmin')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(\"ğŸ“Š DETAYLI PERFORMANS RAPORU\")\n",
    "        print(\"=\"*40)\n",
    "        print(classification_report(y_true, y_pred, target_names=['KadÄ±n', 'Erkek'], digits=4))\n",
    "    else:\n",
    "        print(\"âŒ HATA: Test edilecek dosya bulunamadÄ±!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"best_model_ecapa.pth\"\n",
    "    if Path(model_path).exists():\n",
    "        predictor = GenderPredictor(model_path)\n",
    "        \n",
    "        test_dir = Path(\"/kaggle/working/processed_timit/test/male\")\n",
    "        # Hem kÃ¼Ã§Ã¼k hem bÃ¼yÃ¼k harf ara\n",
    "        all_files = list(test_dir.glob(\"*.wav\")) + list(test_dir.glob(\"*.WAV\"))\n",
    "        \n",
    "        if all_files:\n",
    "            test_file = all_files[0]\n",
    "            label, score = predictor.predict(str(test_file))\n",
    "            print(f\"\\nğŸ§ª Tekil Test: {test_file.name}\")\n",
    "            print(f\"   SonuÃ§: {label} (GÃ¼ven: %{score*100:.2f})\")\n",
    "            \n",
    "            # Tam Analiz\n",
    "            evaluate_on_test_set(predictor)\n",
    "        else:\n",
    "            print(\"âŒ Test klasÃ¶rÃ¼nde hiÃ§ dosya yok! (Yol hatasÄ±?)\")\n",
    "            import os\n",
    "            os.system(\"ls -R /kaggle/working/processed_timit/test\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Model dosyasÄ± bulunamadÄ±. LÃ¼tfen Ã¶nce eÄŸitimi tamamlayÄ±n.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9259704,
     "sourceId": 14497367,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
